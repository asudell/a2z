{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status\n",
    " - The [XPN 90's A to Z](https://xpn.org/program/90s-a-z/) just stated.\n",
    "   I'm redoign things for the new playlist format.\n",
    " - got the playlist fetch/parse working.  Not doing anything with it yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Last year I took a year off and spent more time listening,\n",
    "since the station did a bang up job on stats\n",
    "and I couldn't think of a value add to do on top.\n",
    "Meanwhile, they did a site redesign and my old playlist scraping code is obsolete.\n",
    "If you want to see how this used to happen, \n",
    "or see data for earlier years, see the old [Data Loading Notebook](DataLoading.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Under the coveres, this is mostly [requests](http://docs.python-requests.org/en/master/) to fetch data,\n",
    "which is now json, so we can use the [internal python library](https://docs.python.org/2.7/library/json.html),\n",
    "and [Pandas](https://pandas.pydata.org/) for data munging.  So let's start with the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "import requests \n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, time\n",
    "from os import path, mkdir\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Cache directories\n",
    "When we can, we'll cache data.\n",
    "This is only partially for speed.\n",
    "Checking in the data allows for repetability if sources go away or change.\n",
    "And for some partial results, its useful to publish data.\n",
    "There are others in the XPN community doing data analysis or just asking questions,\n",
    "so csv files are nice to leave around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache_dir = './cache'\n",
    "playlist_cache_dir = path.join(cache_dir, 'playlists')\n",
    "a2z90s_cache_dir = path.join(cache_dir, 'a2z90s')\n",
    "musicbrainz_cache_dir = path.join(cache_dir, 'musicbrainz')\n",
    "data_dir = './data'\n",
    "\n",
    "for d in (cache_dir, playlist_cache_dir, a2z90s_cache_dir,data_dir, musicbrainz_cache_dir):\n",
    "    if not path.exists(d): mkdir(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic XPN Playlist Scraping\n",
    "[XPN](xpn.org) updated their site this year.\n",
    "The [Playlists](https://xpn.org/wxpn-playlists/) are now Json.\n",
    "They also now have Album info, which is great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fetch_daily_playlist(day, cache_dir=None, verbose = False):\n",
    "    \"\"\"\n",
    "    Fetches the XPN playlist for a given date\n",
    "    \n",
    "    Args:\n",
    "        day (datetime.date) : The day to fetch the playlist for\n",
    "        cache_dir (string)  : Path to the cache directory, or None to avoid caching\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame containing Artist, Title, and Album as Strings and Airtime as Timestamp\n",
    "    \"\"\"\n",
    "    songs = pd.DataFrame(None, columns=['Artist', 'Title', 'Album', 'Air Time'])\n",
    "    if cache_dir is not None:\n",
    "        cache_file =  path.join(cache_dir, \"%04d-%02d-%02d.csv\" % \\\n",
    "                                (day.year, day.month, day.day))\n",
    "    if cache_file is not None and path.exists(cache_file):\n",
    "        songs = pd.read_csv(cache_file, encoding='utf-8')\n",
    "        songs['Air Time'] = pd.to_datetime(songs['Air Time'], errors='coerce')\n",
    "        if verbose: print \"Got %d rows from %s\" % (len(songs), cache_file)\n",
    "    else:\n",
    "        # example url\n",
    "        # https://origin.xpn.org/utils/playlist/json/2022-11-30.json\n",
    "        playlist_url = 'https://origin.xpn.org/utils/playlist/json/%s.json' %(day.isoformat())\n",
    "        print playlist_url\n",
    "        page = requests.get(playlist_url)\n",
    "        if verbose: print \"fetching %s returned status %s\" % (day.isoformat(), page.status_code)\n",
    "        # return is a json array of playlist entries\n",
    "        # each playlist entry is a dict of\n",
    "        #  - artist : artists name\n",
    "        #  - song : song title\n",
    "        #  - album : album title\n",
    "        #  - timeslice : string containing an iso date with second granularity in Eastern time\n",
    "        #  - image: url of album cover art\n",
    "        #  - streamPreview : url of a short mp3 outtake from the track\n",
    "        # \n",
    "        # Not all track are music.  But shows like World Cafe or Echos\n",
    "        # put the show name, bound by vertical bars, as the artist, so we can skip them easily enough\n",
    "        track_count = 0\n",
    "        for track in page.json():\n",
    "            if track[\"artist\"][0] == '|':\n",
    "                # skip non-song show titles\n",
    "                continue\n",
    "            if verbose: print (\"adding %s %s %s %s\" % (track['artist'], track['song'], track['album'], \n",
    "                                                       datetime.strptime(track['timeslice'],'%Y-%m-%d %H:%M:%S')))\n",
    "            songs = songs.append({'Artist': track['artist'],\n",
    "                                  'Title': track['song'],\n",
    "                                  'Album': track['album'],\n",
    "                                  'Air Time': datetime.strptime(track['timeslice'],'%Y-%m-%d %H:%M:%S')},\n",
    "                                 ignore_index = True)\n",
    "            if verbose: print \"size = %d\" % len(songs)\n",
    "            track_count += 1\n",
    "        \n",
    "        if verbose: print 'added %d tracks' % (track_count)\n",
    "        if cache_file is not None:\n",
    "            songs.to_csv(cache_file, index=False, encoding='utf-8')\n",
    "            if verbose: print 'write %d rows to %s' % (len(songs), cache_file)\n",
    "        \n",
    "        return songs\n",
    "            \n",
    "                \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_playlist(start, end, cache_dir=None):\n",
    "    \"\"\"\n",
    "    Fetch all the playlist entries for a range of time.\n",
    "    \n",
    "    Args:\n",
    "        start (datetime.datetime) : The inclusive start time to fetch entries for\n",
    "        end (datetime.datetime)   : The exclusive end time to fetch entries for\n",
    "        cache_dir (string)        : path to the cache directory, or None to avoid caching\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe containing Artist, Title, and Album as strings, and Airtime as timestamp\n",
    "    \"\"\"\n",
    "    songs = pd.DataFrame(None, columns=['Artist', 'Title', 'Air Time'])\n",
    "    for day in pd.date_range(start.date(), end.date()):\n",
    "        songs = songs.append(fetch_daily_playlist(day.date(), cache_dir), ignore_index=True)\n",
    "    songs = songs[songs['Air Time'] >= start]\n",
    "    songs = songs[songs['Air Time'] < end]\n",
    "    # sometimes the playlist entries are duplicated\n",
    "    song = songs.drop_duplicates()\n",
    "    songs = songs.sort_values(by = 'Air Time')\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the playlists\n",
    "For now lets do a test run for a few days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://origin.xpn.org/utils/playlist/json/2022-12-01.json\n",
      "got 183 rows\n"
     ]
    }
   ],
   "source": [
    "ninties = fetch_playlist(datetime(2022, 12, 1, 8, 0), datetime.now(),\n",
    "                          playlist_cache_dir)\n",
    "print \"got %d rows\" % len(ninties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air Time</th>\n",
       "      <th>Album</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2022-12-01 08:02:27</td>\n",
       "      <td>A Century Ends</td>\n",
       "      <td>David Gray</td>\n",
       "      <td>A Century Ends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2022-12-01 08:12:21</td>\n",
       "      <td>Lay It Down</td>\n",
       "      <td>Cowboy Junkies</td>\n",
       "      <td>A Common Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2022-12-01 08:16:39</td>\n",
       "      <td>Confessions of a Knife</td>\n",
       "      <td>My Life With Thrill Kill Kult</td>\n",
       "      <td>A Daisy Chain 4 Satan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2022-12-01 08:24:52</td>\n",
       "      <td>Recorded Live for World Cafe 10/15/91</td>\n",
       "      <td>Bruce Cockburn</td>\n",
       "      <td>A Dream Like Mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2022-12-01 08:28:34</td>\n",
       "      <td>Gorgeous George</td>\n",
       "      <td>Edwyn Collins</td>\n",
       "      <td>A Girl Like You</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(ninties.head(5).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air Time</th>\n",
       "      <th>Album</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-01 22:31:43</td>\n",
       "      <td>Blue Lines</td>\n",
       "      <td>Massive Attack</td>\n",
       "      <td>Blue Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-01 22:36:13</td>\n",
       "      <td>Blue Sky Mining</td>\n",
       "      <td>Midnight Oil</td>\n",
       "      <td>Blue Sky Mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 22:45:22</td>\n",
       "      <td>Dancing The Blues</td>\n",
       "      <td>Taj Mahal</td>\n",
       "      <td>Blues Ain't Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 22:49:27</td>\n",
       "      <td>G Love &amp; Special Sauce</td>\n",
       "      <td>G. Love &amp; Special Sauce</td>\n",
       "      <td>Blues Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-01 22:54:57</td>\n",
       "      <td>Phantom Power</td>\n",
       "      <td>The Tragically Hip</td>\n",
       "      <td>Bobcaygeon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(ninties.tail(5).to_html())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
