{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "import requests \n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime, time\n",
    "from os import path, mkdir\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cache_dir = './cache'\n",
    "playlist_cache_dir = path.join(cache_dir, 'playlists')\n",
    "a2z_cache_dir = path.join(cache_dir, 'a2z')\n",
    "a2z70s_cache_dir = path.join(cache_dir, 'a2z70s')\n",
    "a2z80s_cache_dir = path.join(cache_dir, 'a2z80s')\n",
    "xpn2020_cache_dir = path.join(cache_dir, 'xpn2020')\n",
    "musicbrainz_cache_dir = path.join(cache_dir, 'musicbrainz')\n",
    "data_dir = './data'\n",
    "\n",
    "for d in (cache_dir, playlist_cache_dir, a2z_cache_dir, a2z70s_cache_dir,\n",
    "          a2z80s_cache_dir, data_dir, musicbrainz_cache_dir):\n",
    "    if not path.exists(d): mkdir(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_daily_playlist(day, cache_dir=None, verbose = False):\n",
    "    \"\"\"\n",
    "    Fetches the XPN playlist for a given date\n",
    "    \n",
    "    Args:\n",
    "        day (datetime.date) : The day to fetch the playlist for\n",
    "        cache_dir (string)  : Path to the cache directory, or None to avoid caching\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame containing Artist and Title as Strings and Airtime as Timestamp\n",
    "    \"\"\"\n",
    "    songs = pd.DataFrame(None, columns=['Artist', 'Title', 'Air Time'])\n",
    "    if cache_dir is not None:\n",
    "        cache_file =  path.join(cache_dir, \"%04d-%02d-%02d.csv\" % \\\n",
    "                                (day.year, day.month, day.day))\n",
    "    if cache_file is not None and path.exists(cache_file):\n",
    "        songs = pd.read_csv(cache_file)\n",
    "        songs['Air Time'] = pd.to_datetime(songs['Air Time'], errors='coerce')\n",
    "        if verbose: print \"Got %d rows from %s\" % (len(songs), cache_file)\n",
    "    else:\n",
    "        day_s = '%02d-%02d-%04d' % (day.month, day.day, day.year)\n",
    "        page = requests.post('https://xpn.org/playlists/xpn-playlist',\n",
    "                                 data = {'playlistdate': day_s})\n",
    "        if verbose: print \"fetching %s returned status %s\" % (day_s, page.status_code)\n",
    "        \n",
    "        # play list pages claim to be utf-8, but the rare non-ascii character\n",
    "        # is always latin-1\n",
    "        #tree = html.fromstring(page.content.decode('latin-1'))\n",
    "        tree = html.fromstring(page.content)\n",
    "        tracks = tree.xpath('//h3/a/text()')\n",
    "        # not all rows are tracks, some are membership callouts\n",
    "        # but real tracks start with times and are formatted\n",
    "        # HH:MM [am|pm] Artist - Title\n",
    "        # Note that I've seen titles with embedded dashes,\n",
    "        # but so far no artist names with them.  This may be luck.\n",
    "        # Special programs like World Cafe, Echos, ...\n",
    "        # also start with an air time, but don't have useful track info\n",
    "        # but those list the program inside bars\n",
    "        # eg |World Cafe| -  \"Wednesday 11-2-2016 Hour 2, Part 7\"\n",
    "        date_regex = re.compile(\"^\\d{2}:\\d{2}\\s\")\n",
    "        line_count= 0\n",
    "        track_count = 0\n",
    "        for track in tracks:\n",
    "            line_count += 1\n",
    "            if date_regex.match(track) and track[9:10] != '|':\n",
    "                (artist, title) = track[9:].split(' - ', 1)\n",
    "                dt = datetime.strptime(track[:8], '%I:%M %p')\n",
    "                air_time = datetime.combine(day, dt.time())\n",
    "                if verbose: print \"adding %s %s %s\" % (artist, title, air_time)\n",
    "                songs = songs.append({'Artist': artist,\n",
    "                                      'Title': title,\n",
    "                                      'Air Time': air_time},\n",
    "                                     ignore_index = True)\n",
    "                if verbose: print \"size = %d\" % len(songs)\n",
    "                track_count += 1\n",
    "            \n",
    "        if verbose: print 'read %d line and added %d tracks' % (line_count, track_count)\n",
    "        # Drop any duplicates, which are not uncommon\n",
    "        songs = songs.drop_duplicates()\n",
    "        if cache_file is not None:\n",
    "            songs.to_csv(cache_file, index=False, encoding='utf-8')\n",
    "            if verbose: print 'write %d rows to %s' % (len(songs), cache_file)\n",
    "    \n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_playlist(start, end, cache_dir=None):\n",
    "    \"\"\"\n",
    "    Fetch all the playlist entries for a range of time.\n",
    "    \n",
    "    Args:\n",
    "        start (datetime.datetime) : The inclusive start time to fetch entries for\n",
    "        end (datetime.datetime)   : The exclusive end time to fetch entries for\n",
    "        cache_dir (string)        : path to the cache directory, or None to avoid caching\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe containing Artist and Title as strings, and Airtime as timestamp\n",
    "    \"\"\"\n",
    "    songs = pd.DataFrame(None, columns=['Artist', 'Title', 'Air Time'])\n",
    "    for day in pd.date_range(start.date(), end.date()):\n",
    "        songs = songs.append(fetch_daily_playlist(day, cache_dir), ignore_index=True)\n",
    "    songs = songs[songs['Air Time'] >= start]\n",
    "    songs = songs[songs['Air Time'] < end]\n",
    "    # sometimes the playlist entries are duplicated\n",
    "    song = songs.drop_duplicates()\n",
    "    songs = songs.sort_values(by = 'Air Time')\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 1052 rows\n"
     ]
    }
   ],
   "source": [
    "xpn2020 = fetch_playlist(datetime(2020, 12, 10, 8, 0), datetime.now(),\n",
    "                          playlist_cache_dir)\n",
    "print \"got %d rows\" % len(xpn2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Air Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Booker T. &amp; The MG's</td>\n",
       "      <td>Time Is Tight</td>\n",
       "      <td>2020-12-10 08:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>AC/DC</td>\n",
       "      <td>T.N.T.</td>\n",
       "      <td>2020-12-10 08:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Peter Frampton</td>\n",
       "      <td>Show Me the Way</td>\n",
       "      <td>2020-12-10 08:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>The Drifters</td>\n",
       "      <td>Under The Boardwalk</td>\n",
       "      <td>2020-12-10 08:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Adele</td>\n",
       "      <td>Rumor Has It</td>\n",
       "      <td>2020-12-10 08:19:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(xpn2020.head(5).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Air Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>The Moody Blues</td>\n",
       "      <td>Question</td>\n",
       "      <td>2020-12-13 19:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Lucinda Williams</td>\n",
       "      <td>Right In Time</td>\n",
       "      <td>2020-12-13 19:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Four Tops</td>\n",
       "      <td>Bernadette</td>\n",
       "      <td>2020-12-13 19:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>Foghat</td>\n",
       "      <td>Slow Ride</td>\n",
       "      <td>2020-12-13 19:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>Faces</td>\n",
       "      <td>Stay With Me</td>\n",
       "      <td>2020-12-13 19:56:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(xpn2020.tail(5).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_char(s):\n",
    "    for c in s:\n",
    "        if type(c) is str and c.isalpha():\n",
    "            return c.upper()\n",
    "    return s[0]\n",
    "    \n",
    "\n",
    "xpn2020 = xpn2020.join(xpn2020.apply(lambda x: first_char(x[1]), axis=1).to_frame('Letter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "custom_tokenize = RegexpTokenizer(\"[\\w'\\-]+|[^\\w'\\s\\-]\").tokenize\n",
    "\n",
    "xpn2020 = xpn2020.join(xpn2020.apply(lambda x: custom_tokenize(x[1])[0], axis=1).to_frame('First Word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_durations(playlist, end_time=None):\n",
    "    \"\"\"\n",
    "    Estimate the song durations\n",
    "    Args: \n",
    "        playlist (DataFrame): playlist with minimally an 'Air Time' attribute\n",
    "        end_time (datetime): end time of the play list, or None if still going\n",
    "    Return:\n",
    "        modified DataFrame with 'Duration' attribute added.\n",
    "    \"\"\"\n",
    "    \n",
    "    playlist['Duration'] = pd.Series([0 for x in range(len(playlist.index))], index=playlist.index)\n",
    "    previous = None\n",
    "    last_idx = None\n",
    "    for idx, row in playlist.iterrows():\n",
    "        if not previous is None:\n",
    "            if row['Air Time'].date().weekday() == 4 and previous.hour == 11 and row['Air Time'].hour == 12:\n",
    "                # We just fell into a free at noon\n",
    "                playlist.loc[last_idx, 'Duration'] = 60 - previous.minute\n",
    "            else:\n",
    "                # just subtract this start from the previous\n",
    "                delta = row['Air Time'] - previous\n",
    "                playlist.loc[last_idx, 'Duration'] = delta.seconds / 60\n",
    "        previous = row['Air Time']\n",
    "        last_idx = idx\n",
    "\n",
    "    # fixup the last row\n",
    "    if end_time is not None:    \n",
    "        delta = end_time - playlist.loc[last_idx,'Air Time']\n",
    "        playlist.loc[last_idx, 'Duration'] = delta.seconds / 60\n",
    "    \n",
    "    return playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_musicbrainz_data(playlist, min_year = 1900, cache_file = None):\n",
    "    \"\"\"\n",
    "    Add data from the musicbrainz database.  Currently just first year of publication.\n",
    "    The input data frame should contain at least Title and Artist fields\n",
    "    and the resulting dataframe will have a new Year field.\n",
    "    The cache file if used, should have been generated by a previous run of\n",
    "    this function.\n",
    "    Using a cache is strongly encouraged,\n",
    "    as the MusicBrainz search interface is rate limited to one search per second\n",
    "    so this can be very slow for large playlists.\n",
    "    \n",
    "    Args:\n",
    "        playlist (Dataframe) : playlist to update\n",
    "        min_year (int)       : miminum year to consider\n",
    "        cache_file (string)  : path to cache file\n",
    "         \n",
    "    Returns:\n",
    "        Dataframe containing the augmented playlist\n",
    "    \"\"\"\n",
    "    import musicbrainzngs as mb\n",
    "    mb.set_useragent('xpn-a2z', '0.1','https://github.com/asudell/a2z')\n",
    "    \n",
    "    # keep a list of artists named differently\n",
    "    # at MusicBrainz than XPN, so we can 'fix' them\n",
    "    artist_names = {\n",
    "        \"R. E. M.\": \"REM\",\n",
    "        \"Run-DMC\": \"Run-D.M.C.\",\n",
    "        \"The Ramones\": \"Ramones\"\n",
    "    }\n",
    "    \n",
    "    # load the cache if we have one\n",
    "    if cache_file is not None and path.exists(cache_file):\n",
    "        years = pd.read_csv(cache_file)\n",
    "        years = years.drop_duplicates()\n",
    "    else:\n",
    "        years = pd.DataFrame(None, columns=('Title','Artist', 'Year', 'Album'))\n",
    "    \n",
    "    augmented = playlist.merge(years, how = 'left')\n",
    "    \n",
    "    # Lookup any unaugmented rows\n",
    "    new_mb_rows = []\n",
    "    for index, row in augmented[augmented['Year'].isnull()].iterrows():\n",
    "        if row['Artist'] in artist_names:\n",
    "            artist = artist_names[row['Artist']]\n",
    "        else:\n",
    "            artist = row['Artist']\n",
    "        result = mb.search_recordings(row['Title'],\n",
    "                                      artist = artist,\n",
    "                                      status = 'official',\n",
    "                                      strict = True,\n",
    "                                      limit = 25)\n",
    "        rel_year = None\n",
    "        album_name = None\n",
    "        for recording in result['recording-list']:\n",
    "            if recording['release-list']:\n",
    "                for release in recording['release-list']:\n",
    "                    if 'date' in release and len(release['date']) > 0:\n",
    "                        y = int(release['date'].split('-')[0])\n",
    "                        if rel_year is None or rel_year > y:\n",
    "                            if y >= min_year:\n",
    "                                # assume years before 1900 are typos\n",
    "                                rel_year = y\n",
    "                                if release[]\n",
    "        if rel_year is not None:\n",
    "            new_mb_rows.append([row['Title'], row['Artist'], rel_year])\n",
    "    \n",
    "    new_years = pd.DataFrame(new_mb_rows, columns=('Title','Artist', 'Year'))\n",
    "    # if we found new data, resave the cache and rebuild the augmented data\n",
    "    if len(new_years) > 0:\n",
    "        years = years.append(new_years, ignore_index=True)\n",
    "        years = years.drop_duplicates()\n",
    "        if cache_file is not None:\n",
    "            years.to_csv(cache_file, index=False, encoding='utf-8')\n",
    "        augmented = playlist.merge(years, how = 'left')\n",
    "    \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
