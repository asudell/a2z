{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of XPN's AtoZ Playlist\n",
    "\n",
    "One of the cool things about [WXPN](http://xpn.org)\n",
    "is their frequent special programming which is always interesting.\n",
    "This year, they put together a multi-day alphabetical playlist\n",
    "called [XPN's A to Z](http://xpn.org/music-artist/xpn-a-z).\n",
    "As has been the case for a lot of these events,\n",
    "the [#XPNAtoZ](https://twitter.com/search?q=%23XPNAtoZ) tweet stream\n",
    "is as interesting as the music.\n",
    "Initially I was confused by why\n",
    "Johnny Cash's _A Boy Named Sue_ was the 3rd song,\n",
    "when I'd have filed it in the Bs.\n",
    "So, after getting involved in a \n",
    "[twitter exchange](https://twitter.com/brianjgainor/status/803966913483329536)\n",
    "on the topic of treating articles as significant,\n",
    "an idea came to me.\n",
    "I could look at the data to see how words that typically live on stop lists\n",
    "skewed the distribution of the music.\n",
    "Along the way other interesting explorations might turn up.\n",
    "What follows is the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.input').hide();\n",
    "    } else {\n",
    "        $('div.input').show();\n",
    "    }\n",
    "        code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status\n",
    "\n",
    "- At this point, after 18 days we're at Z.\n",
    "  No more surprise.\n",
    "  Well unless we dig them out of the data.\n",
    "- So far the obvious aggregations have been done.\n",
    "  But there still may be interesting opportunities to find patterns. \n",
    "- Graphs have gotten a lot less ugly\n",
    "  since moving to [Seaborn](http://seaborn.pydata.org/) for plotting\n",
    "  and spending a bit of time tidying things up.\n",
    "- I've figured out my issues with [MusicBrainz](https://musicbrainz.org/)\n",
    "  integration, so counts by year are back.  And not clearly wrong\n",
    "  this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "The [AtoZ Playlist page](http://xpn.org/music-artist/xpn-a-z)\n",
    "contains a directory of songs by first letter.\n",
    "Behind the scenes, it makes ReST request to their backend.\n",
    "Originally I said I ought to cache the data.\n",
    "Mostly I was concerned about it going away.\n",
    "But as I integrate data from \n",
    "[MusicBrainz](https://musicbrainz.org/),\n",
    "which rate-limits requests, caching becomes important,\n",
    "though it adds complexity.\n",
    "Data can be pre-cached by running `load_xpn_cache.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os.path as path\n",
    "import csv\n",
    "\n",
    "cache_dir = './cache'\n",
    "xpn_cache = path.join(cache_dir, 'xpn')\n",
    "\n",
    "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "letters_so_far = list(alphabet)[:26]\n",
    "\n",
    "playlist = pd.DataFrame(None, columns = ('Title', 'Artist'))\n",
    "for letter in letters_so_far:\n",
    "    cache_file = path.join(xpn_cache, '%s.csv' % letter)\n",
    "    if path.exists(cache_file):\n",
    "        df = pd.read_csv(cache_file)\n",
    "    else:\n",
    "        rows = []\n",
    "        page = requests.get('http://xpn.org/static/az.php?q=%s' %  letter)\n",
    "        tree = html.fromstring(page.content)\n",
    "        songs = tree.xpath('//li/text()')\n",
    "        for song in songs:\n",
    "            rows.append(song.split(' - ', 1))\n",
    "        df = pd.DataFrame(rows, columns = ('Title', 'Artist'))\n",
    "        df.to_csv(cache_file, index=False)\n",
    "    playlist = playlist.append(df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup and Enrichment\n",
    "\n",
    "First of all there are some duplicates in the data set.\n",
    "We'll clean those up before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(playlist.loc[playlist.duplicated()].to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we delete those.  \n",
    "We also add a few artificial columns to make reporting easier.\n",
    "First Letter and First Word are, well the first letter and word of the title.\n",
    "\n",
    "For what it's worth, \"first word\" turns out to be a harder problem that it might seem.\n",
    "For way more detail than a normal human would want,\n",
    "see the [Word Splitting](Word Splitting.ipynb) notebook.\n",
    "Short version, any sequence of letters or apostrophes is a word\n",
    "for our purposes.\n",
    "\n",
    "We can also do sentiment analysis on the titles.\n",
    "Song titles are not exactly idiomatic English,\n",
    "ideally we would build a training model manually.\n",
    "But for expediency we can try \n",
    "[TextBlob](https://textblob.readthedocs.io/en/dev/)\n",
    "a convenience library that sits on top of\n",
    "[NLTK](http://www.nltk.org/), and comes with a pre-trained model.\n",
    "\n",
    "Finally we can search [MusicBrainz](https://musicbrainz.org/)\n",
    "for likely recordings matching the artist and title\n",
    "and use that to make a good guess \n",
    "at the year the song was first published.\n",
    "Because the MusicBrainz interface is rate limited,\n",
    "this can be slow.\n",
    "Running the whole play list is over an hour.\n",
    "So we're only use pre-cached data here.\n",
    "To see how it gets there see `load_mb_cache.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop dups\n",
    "playlist = playlist.drop_duplicates()\n",
    "\n",
    "# First is the first letter of the title\n",
    "playlist = playlist.join(playlist.apply(lambda x: x[0][0].upper(), axis=1).to_frame('First Letter'))\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "custom_tokenize = RegexpTokenizer(\"[\\w'\\-]+|[^\\w'\\s\\-]\").tokenize\n",
    "\n",
    "# First Word, extract the 'first word' of the title\n",
    "playlist = playlist.join(playlist.apply(lambda x: custom_tokenize(x[0])[0], axis=1).to_frame('First Word'))\n",
    "\n",
    "# Sentiment Analysis\n",
    "# Polarity runs -1.0 (negative) ... +1.0 (postive) sentiment\n",
    "# Subjectivity runs 0.0 .. 1.0\n",
    "# Note apply needs to run on a 2xN matrix to treat the result\n",
    "# as a dataframe, otherwise there's no point in selecting the \n",
    "# Artist column\n",
    "from textblob import TextBlob\n",
    "sentiment = playlist[['Title', 'Artist']].apply(lambda x: list(TextBlob(x[0]).sentiment),\n",
    "                           axis=1)\n",
    "sentiment.columns = ['Polarity', 'Subjectivity']\n",
    "playlist = playlist.join(sentiment)\n",
    "\n",
    "# Add Album data from MusicBrainz\n",
    "# This api is rate limited to about 1 request/sec\n",
    "# running the whole list will take well over an hour\n",
    "# we rely completely on pre-loading the cache here\n",
    "# see load_mb_cache.py for how stuff gets there\n",
    "mb_cache = path.join(cache_dir, 'musicbrainz', 'song_years.csv')\n",
    "if path.exists(mb_cache):\n",
    "    years = pd.read_csv(mb_cache)\n",
    "else:\n",
    "    years = pd.DataFrame(None, columns=('Title','Artist', 'Year'))\n",
    "\n",
    "# Join that up to a copy of the play list\n",
    "playlist = playlist.merge(years, how='left')\n",
    "playlist['Year'] = playlist['Year'].fillna(0.0).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the resulting dataframe has seven fields:\n",
    "Title, Artist, First Letter, First Word,\n",
    "Sentiment Polarity and Subjectivity,\n",
    "and finally Year of publication.\n",
    "Before diving in, just to get perspective,\n",
    "here are some basic stats on the data and a dump of the first and last few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(playlist.describe(include='all', percentiles=[]).to_html(na_rep=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HTML(playlist.head(5).to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(playlist.tail(5).to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs by Letter\n",
    "\n",
    "It's the simplest thing one can look at.\n",
    "And I wouldn't think it all that interesting.\n",
    "But given how uneven the distribution has been,\n",
    "I thought it might be interesting.\n",
    "And there have been a few \"how long with th I's go\"\n",
    "side conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.set_color_codes('pastel')\n",
    "sns.countplot(y='First Letter', data=playlist, color='b')\n",
    "ax.set(xlabel=\"Songs Played\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Frequent Artists\n",
    "\n",
    "Even this early in the playlist,\n",
    "some artists show up often.\n",
    "This might say something about the music the station plays,\n",
    "or the listeners as much of this list comes from previous \n",
    "playlists like \"885 best songs of all time\"\n",
    "or my favorite, the \"85 worst songs of all time.\"\n",
    "For the moment, let's just look at the most frequent dozen or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = playlist['Artist'].value_counts()\n",
    "artists = pd.DataFrame(zip(c.keys().tolist(), c.tolist()),\n",
    "                       columns=('Artist', 'count'))\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.set_color_codes('pastel')\n",
    "sns.barplot(y='Artist', x='count', data=artists.head(25), color='b')\n",
    "ax.set(xlabel=\"Appearences in the Playlist (so far)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Titles\n",
    "From the titles alone, covers and songs that just happen to have the same title\n",
    "look the same.\n",
    "But even early on, the number of duplicate titles\n",
    "was more than I'd have expected.\n",
    "And a few are more than just duplicated.\n",
    "In fact, it's crazy that there were four songs called \"Crazy\",\n",
    "that that's in a 9 way tie for 3rd place,\n",
    "and \"Home\" and \"Hold on\" have 5 instances each.\n",
    "\n",
    "What I can't tell is if this all says that there are a fair number of covers in the list,\n",
    "or if artists just are not that creative at picking names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Distribution of Titles\n",
    "\n",
    "Since there are a lot of duplicate titles,\n",
    "it might be easier to start by looking at the overall distribution.\n",
    "That is, how many titles  show up 2, 3, or more times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a Datafrae of Unique Titles to Appearence counts\n",
    "c = playlist['Title'].value_counts()\n",
    "title_counts = pd.DataFrame(zip(c.keys().tolist(), c.tolist()),\n",
    "                           columns=('Title', 'Count'))\n",
    "f, ax = plt.subplots(figsize=(6, 3))\n",
    "sns.set_color_codes('pastel')\n",
    "sns.countplot(y='Count', data=title_counts[title_counts['Count'] >2],\n",
    "              color='b')\n",
    "ax.set(ylabel=\"Repetitions of a Title\", xlabel=\"Instances in Playlist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Popular Titles\n",
    "Of course we want to know what those titles were.\n",
    "At least the really popular ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(title_counts[title_counts['Count'] > 3].to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Most Frequent First Words\n",
    "\n",
    "This is the question that started me down this path.\n",
    "How much do common \"stop words\" like articles or propositions \n",
    "skew the distribution?\n",
    "Or do so many songs start with a small set of words\n",
    "that no amount of pruning would even the distribution out?\n",
    "Here's an early look a the top 25 first words.\n",
    "Yes, \"A\" *was* up there.\n",
    "But even early on it wasn't in the lead.\n",
    "Perhaps my initial concerns were unfounded.\n",
    "Except that the long reign of \"I\" as the top first word has ended\n",
    "as, after almost 18 hours of air time, \"The\" overtook it,\n",
    "and and kept on going.\n",
    "So, in the end the playlist could have been come out different\n",
    "had articles not be used to index titles.\n",
    "It's just that \"The\" mattered a lot more than \"A.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = playlist['First Word'].value_counts()\n",
    "words = pd.DataFrame(zip(c.keys().tolist(), c.tolist()),\n",
    "                       columns=('First Word', 'count'))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.set_color_codes('pastel')\n",
    "sns.barplot(y='First Word', x='count', data=words.head(20), color='b')\n",
    "ax.set(xlabel=\"Appearences in the Playlist (so far)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same data as a word cloud,\n",
    "though the python `wordcloud` package does a few things work against us\n",
    "and are not customizable in the released version.\n",
    "In particular, it kills of the I's and A's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "firsts = playlist.apply(lambda x: custom_tokenize(x[0])[0], axis=1)\n",
    "wordcloud = WordCloud(max_font_size=40, stopwords='').generate(' '.join(firsts.tolist()))\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Sentiment Analysis rates text on how positive or negative is.\n",
    "How happy are the songs XPN plays?\n",
    "How many are angry (or more likely sad)?\n",
    "The vast majority of the titles are neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.distplot(playlist['Polarity'])\n",
    "ax.set(xlabel=\"Sentiment\", ylabel=\"Number of Songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's easier to see the distribution\n",
    "if we ignore the neutral songs.\n",
    "Here we see there's a decent spread,\n",
    "with a reasonably strong skew towards the positive.\n",
    "Perhaps songwriters often mine pain for themes,\n",
    "but we prefer to play happy songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.distplot(playlist[playlist['Polarity'] != 0]['Polarity'])\n",
    "ax.set(xlabel=\"Sentiment (omitting zero values)\", ylabel=\"Number of Songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some of the most positive songs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(playlist.sort_values('Polarity', ascending=False)[['Artist', 'Title', 'Polarity']].head(10).to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(playlist.sort_values('Polarity', ascending=True)[['Artist', 'Title', 'Polarity']].head(10).to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of Evil there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Were the Songs From\n",
    "\n",
    "Were the songs in the playlist all classic rock\n",
    "or where they all pretty current?\n",
    "We can tell by grouping by the Years we've extracted \n",
    "via lookups on MusicBrainz.\n",
    "We can't find every track there,\n",
    "but we can find 5481 out of 5673 and that's not bad considering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "c = playlist['Year'].value_counts()\n",
    "year_counts = pd.DataFrame(zip(c.keys().tolist(), c.tolist()),\n",
    "                       columns=('Year', 'Count'))\n",
    "f, ax = plt.subplots(figsize=(6, 14))\n",
    "sns.set_color_codes('pastel')\n",
    "sns.barplot(y='Year', x='Count',\n",
    "            data=year_counts[year_counts['Year'] > 1910],\n",
    "            orient='h', color='b')\n",
    "ax.set(xlabel=\"Number of Songs\", ylabel=\"Year of Publication\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for years is based on an imperfect match,\n",
    "so it might not really be 100%.\n",
    "But it passes enough of a sniff test that\n",
    "it's worth using.\n",
    "\n",
    "There's a strong bias for late 60s and early 70's.\n",
    "But it's a pretty wide thick distribution.\n",
    "This is an audience that keeps up with new music.\n",
    "\n",
    "Oh, those entries for 2017.  They are legitimate, sort of.\n",
    "_The Castle_ by the Flaming Lips will be on _Oczy Mlody_,\n",
    "due out Jan 17.\n",
    "And _Astral Plane_ by Valerie June will be on _The Order of Time_,\n",
    "due out Jan 27.\n",
    "Since the methodology we've used is to use the publish date\n",
    "of the oldest physical release that contained a track for\n",
    "the same title and the same artist,\n",
    "we end up treating early downloads as being \"from the future.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Is A-Z Different\n",
    "\n",
    "Because it is curated from existing XPN playlists,\n",
    "the A-Z playlist might not be 100% representative of\n",
    "the day to day programming.\n",
    "There is a [http://xpn.org/playlists/xpn-playlist](XPN Playlist) page,\n",
    "and while it doesn't have a ReST interface for navigation like \n",
    "the [http://xpn.org/music-artist/xpn-a-z](A-Z Playlist) page does,\n",
    "it isn't very hard to screen scrape.\n",
    "So, we can load say the previous months playlist \n",
    "and do some comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "history_cache = path.join(cache_dir, 'historical')\n",
    "\n",
    "historical_playlist = pd.DataFrame(None, columns=('Artist', 'Title'))\n",
    "days = pd.date_range(start='11/1/2016', end='11/29/2016')\n",
    "for day in days:\n",
    "    day_s = \"%02d-%02d-%04d\" % (day.month, day.day, day.year)\n",
    "    cache_file = path.join(history_cache, \"%s.csv\" % day_s)\n",
    "    if path.exists(cache_file):\n",
    "        df = pd.read_csv(cache_file)\n",
    "    else:\n",
    "        rows = []\n",
    "        page = requests.post('http://xpn.org/playlists/xpn-playlist',\n",
    "                             data = {'playlistdate': day_s})\n",
    "        tree = html.fromstring(page.content)\n",
    "        tracks = tree.xpath('//h3/a/text()')\n",
    "        # not all rows are tracks, some are membership callouts\n",
    "        # but real tracks start with times and are formatted\n",
    "        # HH:MM [am|pm] Artist - Title\n",
    "        # Special programs like World Cafe, Echos, ...\n",
    "        # also start eith time, but don't have useful track info\n",
    "        # but those list the program inside bars\n",
    "        # eg |World Cafe| -  \"Wednesday 11-2-2016 Hour 2, Part 7\"\n",
    "        date_regex = re.compile(\"^\\d{2}:\\d{2}\\s\")\n",
    "        for track in tracks:\n",
    "            if date_regex.match(track) and track[9:10] != '|':\n",
    "                rows.append(track[9:].split(' - ', 1))\n",
    "        df = pd.DataFrame(rows, columns = ('Artist', 'Title'))\n",
    "        df.to_csv(cache_file, index=False)\n",
    "\n",
    "    historical_playlist = historical_playlist.append(df, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which Artists are Over or Under Represented\n",
    "\n",
    "One thing we can do is take the the artist counts from above\n",
    "and compare it the historical playlist we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from sklearn import preprocessing\n",
    "c = playlist['Artist'].value_counts()\n",
    "az_artists = pd.DataFrame(zip(c.keys().tolist(), c.tolist()),\n",
    "                         columns=('Artist', 'Frequency'))\n",
    "xform = preprocessing.MinMaxScaler()\n",
    "c = historical_playlist['Artist'].value_counts()\n",
    "hist_artists = pd.DataFrame(zip(c.keys().tolist(), c.tolist()),\n",
    "                           columns=('Artist', 'Frequency'))\n",
    "artist_freq = az_artists.merge(hist_artists, how='outer',\n",
    "                               on = 'Artist',\n",
    "                               suffixes=('_az', '_hist'))\n",
    "artist_freq[['Frequency_az', 'Frequency_hist']] \\\n",
    " = xform.fit_transform(artist_freq[['Frequency_az', 'Frequency_hist']].fillna(0))\n",
    "\n",
    "artist_freq['Difference'] = artist_freq['Frequency_az'] - artist_freq['Frequency_hist']\n",
    "artist_freq = artist_freq.sort(columns='Difference')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In November the most popular artists were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.set_color_codes('pastel')\n",
    "sns.barplot(y='Artist', x='Frequency', data=hist_artists.head(25), color='b')\n",
    "ax.set(xlabel=\"Appearences in November\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artists played more frequently in the A-Z playlist than the preceding month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(artist_freq.head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artists played less frequently in the playlist than the precdeing month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(artist_freq.tail().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which Years Are More Frequent\n",
    "\n",
    "The A-Z playlist skews heavily to the late 60's and early 70's.\n",
    "How representative is that of the day to day play list?\n",
    "A lot of us listen to XPN to be introduced to new music,\n",
    "yet we fondly remember our high school years.\n",
    "We can join the historical data from November up against \n",
    "the MusicBrainz data as we did above.\n",
    "This time there are fewer matches and over 800 of 3.5K titles can't be found.\n",
    "Still it gives us a sense of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb_hist_cache = path.join(cache_dir, 'musicbrainz', 'hist_years.csv')\n",
    "if path.exists(mb_hist_cache):\n",
    "    hist_years = pd.read_csv(mb_hist_cache)\n",
    "else:\n",
    "    hist_years = pd.DataFrame(None, columns=('Artist','Title', 'Year'))\n",
    "\n",
    "# Join that up to a copy of the play list\n",
    "historical_playlist = historical_playlist.merge(hist_years, how='left')\n",
    "historical_playlist['Year'] = historical_playlist['Year'].fillna(0.0).astype(int)\n",
    "HTML(historical_playlist.head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot that as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = historical_playlist['Year'].value_counts()\n",
    "hist_year_counts = pd.DataFrame(zip(c.keys().tolist(), c.tolist()),\n",
    "                                columns=('Year', 'Count'))\n",
    "f, ax = plt.subplots(figsize=(6, 14))\n",
    "sns.set_color_codes('pastel')\n",
    "sns.barplot(y='Year', x='Count',\n",
    "            data=hist_year_counts[hist_year_counts['Year'] > 1950],\n",
    "            orient='h', color='b')\n",
    "ax.set(xlabel=\"Number Tracks Played In November\", ylabel=\"Year of Publication\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well tha's a a lot different!\n",
    "Goodby 1970, hello 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Availability\n",
    "\n",
    "The code for this project is in [my git hub repo](https://github.com/asudell/a2z).\n",
    "The notebook its self is [published on nbviewer](http://nbviewer.jupyter.org/github/asudell/a2z/blob/master/AtoZ.ipynb)\n",
    "\n",
    "## License\n",
    "\n",
    "This project is licensed under a\n",
    "[Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).\n",
    "You are free to use for commercial or non-commercial purposes,\n",
    "so long as you attribute the source and also allow sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Efforts\n",
    "\n",
    "Apparently I'm not the only one who thought to do something like this.\n",
    "Checkout [Bruce Segal's work](https://public.tableau.com/profile/besegal#!/vizhome/BESegalWXPNAtoZPlayListPublished/XPNAtoZFindYourSongfromAtoZ)\n",
    "as well as [Lena Bartel's work](https://public.tableau.com/profile/lena.bartell#!/vizhome/XPN_AtoZ/XPNA-ZPlaylistData).\n",
    "They explore the same topics, plus a few more.\n",
    "And both use Tableau, which is very nice looking.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
